% \loop\iftrue%
% \errmessage{This article is copyrighted by ___ and should not be TeXed}%
% \repeat%

\documentclass{ifacconf}  % Comment this line out
\usepackage{natbib}        % required for bibliography

% \documentclass[a4paper, 10 pt, conference]{ieeeconf}  % Comment this line out
% \IEEEoverridecommandlockouts%
\pdfminorversion=4%

\input{preamble}
\input{math}
\input{symbols}

% \usepackage{flushend}% to equalize last page %%% use when text complete


\draft% show todos in red
% \final% give error if there is todos
% \comments% blank right column to make comments in pen & paper

% \newcommand{\id}{}
% \newcommand{\price}{31.00}
% \pubid{\begin{minipage}{\textwidth}\ \\[50pt]\centering
%   \copyright{} 20XX \_\_\_\_.\\
%   Personal use is permitted, but republication/redistribution requires permission.\\
%   % See https://www.ieee.org/publications/rights/index.html for more information.% if IEEE
% \end{minipage}
% }
% \makeglossaries

\begin{document}

\begin{frontmatter}
\title{\LARGE \bf
  Expectation-Maximization based defense mechanism for distributed Model Predictive Control
}

\author[First]{Rafael Accácio Nogueira}
\author[First]{Romain Bourdais}
\author[First]{Simon Leglaive}
\author[First]{Hervé Guéguen}
\address[First]{IETR-CentraleSupélec, 35510 Cesson-Sévigné, Ille-et-Vilaine, France\\
{\tt\small \{rafael-accacio.nogueira, romain.bourdais, simon.leglaive, herve.gueguen\}
@centralesupelec.fr}}

% \thanks{\centering The authors are with  \newline {\tt\small
% }\newline

% % <-this % stops a space
% \thanks{\centering The authors are with IETR-CentraleSupélec, 35510\newline Cesson-Sévigné, Ille-et-Vilaine, France \newline {\tt\small
% \{rafael-accacio.nogueira, romain.bourdais, herve.gueguen\}
% @centralesupelec.fr}\newline
% }%
% }

% \maketitle
% \IEEEpeerreviewmaketitle%
% \thispagestyle{empty}
% \pagestyle{empty}

\begin{abstract}% Abstract of not more than 250 words.
  \todo[write abstract]{
  In distributed predictive control structures, communication among agents is required to achieve a consensus and approach an optimal global behavior. Such negotiation mechanisms are sensitive to attacks on these exchanges.
  This paper proposes a monitoring scheme that detects and mitigates these attacks' effects in a resource allocation framework.
  The performance of the proposed method is illustrated through simulations of the temperature control of multiple rooms under input power constraints.
}
\end{abstract}

\begin{keyword}
  Model predictive and optimization-based control,
  Distributed control and estimation,
Large scale optimization problems
\end{keyword}

\end{frontmatter}

\section{INTRODUCTION}
The information collected, processed, and transmitted within \cps{} impacts physical systems whose proper functioning is essential for society, like energy networks, industrial processes, water production plants, etc..
Attacks in those critical infrastructures, such as Stuxnet, increased awareness for cyber-security of \cps{}.

Given the complexity, scale and even geographic location of these structures, it is necessary to adopt control structures that are decentralized rather than \todo{monolithic}.
For these systems, a set of controllers are designed to ensure the safe and efficient operation of the facilities collectively.

This operation is done cooperatively, where the controllers exchange information with each other.
This approach can be used, for example, for the voltage regulation of electrical networks~\citep{HansEtAl2019}, and the production-consumption balance in these same networks~\citep{HerreraEtAl2015}.
Multi-agent systems~\citep{KantamneniEtAl2015} or \dmpc{}~\citep{MaestreEtAl2014} are standard tools to design these controllers.

When one of these controllers is attacked, it can result in the violent destruction of the corrupted element (perhaps the whole system), or more subtly, it can lead to deviant behavior that is more difficult to detect.
Usually the attacks aim to de-optimize the global operation by benefiting/prejudicing some specific group of controllers, or to \todo{slowly} lead the system towards a state of malfunction/instability~\todo[use other]{\citep{NogueiraEtAl2021}}.

With this in mind, a few articles have focused on safety in \dmpc{} frameworks, presenting vulnerabilities of different frameworks, such as lagrange-based decomposition~\citep{VelardeEtAl2017}, and Jacobi-Gauss decomposition~\citep{ChanfreutEtAl2018}.

The authors in~\cite{VelardeEtAl2017} highlight the complexity of the problems. A modification of a local goal, the hacking of communication,
or the failure of one of the agents are events that disrupt global behavior.

Some strategies are presented to mitigate the effects of such event,
for instance dismissing extreme values as in~\cite{VelardeEtAl2017}, or
using secure scenarios based on reliable historical data~\cite{VelardeEtAl2017a}.
The most recent~\cite{MaestreEtAl2021} presents ways to generate these scenarios.

Our previous work~\citep{NogueiraEtAl2021} proposed a framework dedicated to
sharing resource algorithms (primal decomposition), and shown its vulnerabilities.
More precisely, \fdi{} in the communication
between a coordinator and local constraint-free agents bound by global equality constraints. The paper also proposed a safe algorithm based on data reconstruction to mitigate the effects.

In this paper, we propose an extension of our approach by including local constraints and changing the global constraints.
This extension profoundly changes the complexity, as the exchanges between the
agents and the coordinator are no longer characterized by an affine functions
but by \pwa{} functions.
This leads not only to a combinatorial explosion but also to a parametric identification challenge.
To overcome this problem, we propose using a learning method based on the \EM{} algorithm~\citep{DempsterEtAl1977}, which allows us to estimate the corruption
mechanism and correct it if necessary.

\todo{The paper is constructed as follows}

\emph{Notation:}
In this paper, $\norm{\cdot}$, $\norm{\cdot}_{F}$, and $\norm{\vec{v}}_{Y}$ represent the $\ell_{2}$ norm, the Frobenius norm and the weighted norm $\norm{Y^{\frac{1}{2}}\vec{v}}$.
$\Proj^{\set{T}}(\cdot)$ is the Euclidean projection onto set $\set{T}$.
% $\card{x}$ is the number of elements in $x$.
$\kron{}{}$, and $\hadamard{}{}$ are the Kronecker and Hadamard products.
$\vectorize{A}$ vectorizes matrix $A$.
${n\mathbin{:}i\mathbin{:}j}$ is a row vector builder with elements $\{n,n+i,\dots,n+mi\}$, where ${m=\mathrm{truncate}(\frac{j-n}{i})}$, and ${n\mathbin{:}j}$ is equal to ${n\mathbin{:}1\mathbin{:}j}$.
$[A,B]$ and $[A;B]$ are horizontal and vertical concatenation of matrices.
${\0_{m}=0_{m\times 1}}$ (${\1_{m}=1_{m\times 1}}$), where
$0_{m\times n}$ ($1_{m\times n}$) is a $0$ ($1$) filled \mbox{$m$-by-$n$} matrix.
$\indicator{x}$ is the indicator function returning $1$ if $x$ is true and $0$ otherwise.
$\preceq$ is the component-wise less or equal for vectors and matrix inequality for matrices in ${\symmetric^{n}=\setbuild{X:\R^{n\times n}}{X'=X}}$.
${\defpos^{n}=\setbuild{X:\symmetric^{n}}{X\succ 0}}$, ${\semidefpos^{n}=\setbuild{X:\symmetric^{n}}{X\succeq 0}}$.
$I_{c}$ is the identity matrix of size $c$.
$A^{\dagger}$ is the generalized inverse ${{(A^{T}A)}^{-1}A^{T}}$.
$\determinant{A}$ is the determinant of $A$.
A vector $\vec{v}_{i}$, correspond to the $i$-th agent, and these vectors can be stacked in a vector $\vec{v}$.
$\random{a},\random{A},\randomvec{a}$ are random variables, scalar, matrix and vector respectively.
$\expectation{\random{x}}$ is the expected value of $\random{x}$, and $\probability{A \mid B}$ is the conditional probability of $A$ given condition $B$.
% $\pdf{\cdot}$ is a probability density function.
${\diag(A_{1},\dots,A_{N})}$ corresponds to a block diagonal matrix.

\section{Problem Statement}\label{sec:PS}
In this section we present an algorithm to decompose a \mpc{} problem based on the primal decomposition \citep{BoydEtAl2015}, and a vulnerability of the decomposition that can be exploited by a malicious agent.

\subsection{Model Predictive Control}\label{ssec:MPC}
Let us consider a system composed of $M$ discrete-time linear time-invariant agents, whose dynamics are ruled by:
\begin{equation}
\begin{matrix}
  \label{eq:systems}
\vec{x}_{i}[k+1]&=&A_{i}\xik &+& B_{i}\uik\\
\vec{y}_{i}[k+1]&=&C_{i}\xik &&
\end{matrix},
\end{equation}
with $\vec{x}_{i}[k]:\R^{n_{x}}$, $\vec{u}_{i}[k]:\R^{n_{u}}$ and $\vec{y}_{i}[k]:\R^{n_{y}}$.

Each agent's input $\uik$ is constrained by
\begin{equation}
  \label{eq:u_local_constraints}
  \0_{n_{u}}\preceq\uik\preceq\vec{u}_{\max},
\end{equation}
with ${\umax:\R^{n_{u}}}$.
The $M$ agents are coupled by global input constraints with weighting matrices \todo{${\Gamma_{i}:\semidefpos^{n_{u}}}$}:
\begin{equation}
  \label{eq:global_constraint}
  \sum^{\nsubsystems}_{i=1}\Gamma_{i}\uik\preceq\umax.
\end{equation}


The overall system is controlled by a \mpc{}, which predicts the dynamics for a finite prediction horizon $\predhorz$ and computes the optimal input by solving the following problem:
\begin{equation}\label{eq:GOP}
\resizebox{.88\columnwidth}{!}{$
\begin{matrix}
\underset{\useq}{\mathrm{minimize}}&\resizebox{0.35\textwidth}{!}{$\overbrace{\sum\limits^{M}_{i=1} \overbrace{\sum_{j=1}^{\predhorz} \norm{\mpcvec{v}[i][k+j][k]}^{2}_{Q_i}+\norm{\mpcvec{u}[i][k+j-1][k]}^{2}_{R_i}}^{\textstyle{} \obji}}^{\textstyle{} \globobj}$}\\
\mathrm{subject~ to}&~\eqref{eq:systems},\eqref{eq:u_local_constraints}\ \mathrm{and}\ \eqref{eq:global_constraint}
\left\}\small
\begin{aligned}
  &\forall i\in \{1:\nsubsystems\}\\
  &\forall j\in \{1:\predhorz\}
\end{aligned}\right.,

\end{matrix}
  $}
% \label{eq:dmpcModLOP}
\end{equation}
where ${Q_{i}:\semidefpos}$, ${R_{i}:\defpos}$, and $\vik$ is a control objective.
$\optglobobj$ denotes the optimal value of the objective function for the the optimal control sequences ${\optuiseq}$.
The problem in~\eqref{eq:GOP} is solved at each time $k$, and the ${\optuikk}$ are applied in their respective subsystem $i$, following a \rhs{}.

Due to the monolithic aspect of~\eqref{eq:GOP}, solving it at each time $k$ can be quite challenging, since the prediction horizon and the number of agents can be large making the process computationally intensive. Another issue that can arise is the fact that the complete information (${\set{I}_{i}=\{A_{i},B_{i},C_{i},\vec{v}_{i}[k],Q_{i},R_{i}\}}$) from all the subsystems is needed to solve the problem,
which can be viewed negatively in a confidentiality point of view.

One can see that if it were not for the global constraints~\eqref{eq:global_constraint}, the problem would be easily decomposed in $M$ parts and solvable in parallel.
So, we use the \emph{primal decomposition} method, sometimes called \emph{quantity decomposition} or \emph{resource allocation}, with wich we can profit from the parallelism, while avoiding the use of the complete information $\set{I}_{i}$.

\subsection{Primal Decomposition based dMPC}\label{ssec:dMPC}

The technique consists of decomposing the monolithic \mpc{} in~\eqref{eq:GOP} into $M$ modified \mpc{} problems~\eqref{eq:DOP_local}, called \emph{local problems}, which can be solved in parallel by each subsystem, and a \emph{master problem}~\eqref{eq:DOP_master}, which is equivalent to the global problem and is solved by a coordinator.
\begin{subequations}
  \begin{equation}
    \left.
      \small
      \begin{aligned}
        J_{i}^{\star}(\thetaik)&=\underset{\uiseq}{\mathrm{minimize}} \obji\\
        \mathrm{s.t.} &\quad\eqref{eq:systems}\ \&\ \eqref{eq:u_local_constraints}\\
        &\quad\Gamma_{i}\uik\preceq\qik:\dik\\
      \end{aligned}
    \right\}
    \small
    \begin{aligned}
      &\forall i\in \{1\mathbin{:}\nsubsystems\}\\
      &\forall j\in \{1\mathbin{:}\predhorz\}
    \end{aligned}
    \label{eq:DOP_local}
  \end{equation}
  \begin{equation}
    \small
    \begin{aligned}
      J^{\star}&=\underset{\qiseq}{\mathrm{minimize}}\sum^{\nsubsystems}_{i=1} J^{\star}_i(\qik)\\
      \mathrm{s.t.} &\quad \sum_{i=1}^{\nsubsystems}\qik\preceq\umax,\ \forall j\in\{1\mathbin{:}\predhorz\}\\
      &\quad \qik[k]\succeq\0_{n_{u}}\text{, } \forall i\in\{1\mathbin{:}M\},\forall j\in\{1\mathbin{:}\predhorz\}
    \end{aligned}
    \label{eq:DOP_master}
  \end{equation}
\end{subequations}
The modified \mpc{} problems in~\eqref{eq:DOP_local} are created by exchanging the $\vec{u}_{\max}$ in~\eqref{eq:global_constraint} by vectors $\qik$, where which one corresponds to the quantity of the total resource $\vec{u}_{\max}$ that is allocated to agent $i$ in time $[k]$ for each prediction $j$, thus the names \emph{resource allocation} and \emph{quatity decomposition}. This new set of constraints have associated dual variables ${\dik\succeq\0_{n_{u}}}$. The sequence of this variables variables ${\qiseq}$ and ${\diseq}$ can be aggregated in vectors ${\thetaik=\kron{\1_{\predhorz}}{\qik}}$, and ${\lambdaik=\kron{\1_{\predhorz}}{\dik}}$.

The \emph{master problem} finds the optimal allocation sequences $\optthetai$ by using a projected sub-gradient method:
\begin{equation}
  \label{eq:projectedSubgradient}
\vec{\theta}[k]\pplusone=\Proj^{\set{H}}(\vec{\theta}[k]\p-\rho\p\vec{g}[k]\p),
\end{equation}
where ${\set{H} = \setbuild{\vec{\theta}}{I_{c}^{M}\vec{\theta}\preceq \vec{U}_{\max}\ \&\&\ \vec{\theta}\succeq\0 }}$, being ${c=\predhorz n_{u}}$, ${I_{c}^{M}=\kron{\1_{M}}{I_{c}}}$, ${\vec{U}_{\max}=\kron{\1_{\predhorz}}{\vec{u}_{\max}}}$, $(p)$ is a given step in the iterative process and $\vec{g}\p[k]$ is a sub-gradient of the objective of the function problem in~\eqref{eq:DOP_master} in step $(p)$.

From~\cite{BoydEtAl2015}, it is known that $-\lambdaik$ are sub-gradients of objective $J[k]$.
Plugging it in $\vec{g}[k]\p$ we have
\begin{equation}
  \label{eq:thetaNegot}
\vec{\theta}[k]\pplusone=\Proj^{\set{H}}(\vec{\theta}[k]\p+\rho\p\vec{\lambda}[k]\p),
\end{equation}
\newcommand{\negotiation}{\emph{negotiation}}
which henceforth is referred as the \negotiation.

Once the \negotiation{} for a given time $k$ converges, the $\optuikk$ found in the last step of the \negotiation{} are applied in their corresponding agent and then the \rhs{} is followed.

The algorithm to find the optimal $\optthetai[k]$ can be summarized in algorithm~\ref{alg:quantityAlg}, and the exchange between coordinator and agents can be seen in Fig.~\ref{fig:dmpc_graph}.

\begin{algorithm2e}[h]
  \DontPrintSemicolon%
  $p:=0$\;
  Coordinator initializes $\vec{\theta}\p$ \;
  \Repeat{$\|\vec{\theta}^{(p)} -\vec{\theta}^{(p-1)}\|\leq\epsilon$}{
  Subsystems solve~\eqref{eq:DOP_local}, and send $\optlambdai (\thetai\p)$\;
  Coordinator updates allocations~\eqref{eq:thetaNegot}\;
  $p:=p+1$
}
 \caption{Quantity decomposition based \acrlong{dmpc}.}\label{alg:quantityAlg}
\end{algorithm2e}

One can observe that instead of using $\mathcal{I}_{i}$, each agent only sends $\lambdaik$.
An interpretation of $\lambdaik$ is the dissatisfaction of an agent with the resource $\thetaik$ allocated for it, where ${\lambdaik=\0_{c}}$ means total satisfaction.
The coordinator trusts in the authenticity of the $\vec{\lambda}_{i}[k]$ received to update the allocations, but if false data is injected, the \negotiation{} can be driven by a malicious agent that can take advantage of this trust to favor itself at the expense of others or even destabilize the \negotiation{}, as shown in~\cite{NogueiraEtAl2021}.


Our main objective is to mitigate the effects of a given configuration where agents send untrustworthy of the form
\begin{equation*}
\lambdaicheat=\gamma_{i}(\lambdai).
\end{equation*}

\section{Towards a safe dMPC}\label{sec:TSM}

Here we focus on the local problems in~\eqref{eq:DOP_local}, and study how their structure can contribute for a safe dMPC algorithm.

\subsection{Local Problems --- Formal Analysis}\label{ssec:FA}

The \emph{local problems} can be rewritten in a equivalent (same solution) constrained \qp{} form:
\begin{equation}\label{eq:quadratic_case}
\begin{matrix}
\underset{\Uik}{\mathrm{minimize}}& \overbrace{\frac{1}{2} \Uik^T H_i\Uik+{\fik}^T\Uik}^{\textstyle J_{i}(\vec{\theta}_{i})}\\
\mathrm{s.t.}&\bar{\Gamma}_{i}\Uik\preceq\vec{\theta}_{i}[k]:\vec{\lambda}_{i}[k]\\
&\Uik\succeq\0_{c},
\end{matrix}
\end{equation}
where ${\Uik}$ stacks the input prediction sequences, and
${\bar{\Gamma}_{i}=\kron{I_{\predhorz}}{\Gamma_{i}}}$.
The exact values for $H_{i}$ and $\vec{f}_{i}[k]$ vary depending on the control objective $\vec{v}_{i}[k]$. The approach presented in this paper does not depend on the choice of the control objective.
The approach depends only on the fact that $H_{i}:\semidefpos$ does not depend on $k$, while $\fik$ does. Those facts are instrumental for the results in the following sections.

\no{
  We choose reference tracking just to illustrate the approach. With this objective, we have
${\vik=\wik-C_{i}\xik}$, where $\wik$ is the output reference in time $k$, which yields
\begin{equation}
\small\begin{matrix*}[l]
 H_i&=&\mathcal{D}_i^T\bar{Q}_i\mathcal{D}_i+\bar{R}_i\\
\fik&=&\mathcal{D}_i^T\bar{Q}_i(\mathcal{M}_i\xik-\Wik),
\end{matrix*}
\label{eq:matrices}
\end{equation}
where $\Wik$ stacks the setpoint prediction sequence, which is supposed to be constant during the predicted horizon ${\Wik=\kron{\1_{\predhorz}}{\vec{w}_{i}[k]}}$ (no prior information).
${\mathcal{M}_{i}}$  and ${\mathcal{D}_{i}}$ are the prediction matrices of the \mpc{}.
${\bar{Q}_{i}=\kron{I_{\predhorz}}{Q_{i}}}$, and ${\bar{R}_{i}=\kron{I_{\predhorz}}{R_{i}}}$.
}

\begin{figure}[t]
% TODO(accacio): correct image
  \centering
  \begin{tikzpicture}[node distance=1.7cm]
    \tikzset{
      agent/.style={draw,circle,minimum width=1cm,},
      coord/.style={draw,circle,minimum width=1.7cm,very thick}
    }
    % \draw[thick,blue,rounded corners=10pt] (-1.7,1.2) rectangle (1.7,-1.7);
    % \node at (1.2,-1.3) {O};
    % \node (pi) at (-2.5,.5) {$\pi$};
    % \node (phi) at (2.5,-1.) {$\phi_{c}$};

    \node[agent] (a1) {A$_{1}$};
    \node (a2) [right of=a1]  {$\dots$};
    \node[agent] (am) [right of=a2] {A$_{M}$};
    \node[coord] (c) [above of=a2] {Coord};


    \draw[-latex] (a1) to [out=60,in=210] node [sloped,above] {$\vec{\lambda_{1}}$} (c) ;
    \draw[-latex] (c) to [out=-120,in=30] node [sloped,below] {$\vec{\theta}_{1}$} (a1);

    \draw[-latex] (am) to [out=150,in=-60]node [sloped,below] {$\vec{\lambda}_{M}$} (c);
    \draw[-latex] (c) to [out=-30,in=120] node [sloped,above] {$\vec{\theta}_{M}$} (am);

  \end{tikzpicture}
  \caption{Graph representation of Coordinator exchanging with $M$ agents in a \dmpc{} framework.}\label{fig:dmpc_graph}
\end{figure}

As seen in~\cite{BemporadEtAl2002}, the solution for a linear constrained \qp{} problem yields in a \pwa{} function.
Similarly, we can get an explicit solution for its dual variables $\vec{\lambda}_{i}[k]$, which is a \pwa{} function w.r.t. $\vec{\theta}_{i}[k]$:
% \begin{equation}
%   \resizebox{.88\columnwidth}{!}{$
%     \begin{aligned}
%       \label{eq:lambdafuntheta}
%       \lambdaik=
%       \begin{cases}
%         -P_{i}^{1}\thetaik-\vec{s}_{i}^{1}[k]&\text{if}\ G^{1}[k]\thetaik \preceq b^{1}[k] \\
%         \qquad\quad \vdots&\qquad\quad \vdots\\
%         -P_{i}^{N}\thetaik-\vec{s}_{i}^{N}[k]&\text{if}\ G^{N}[k]\thetaik \preceq b^{N}[k] \\
%       \end{cases}
%     \end{aligned}
%     $}
% \end{equation}
\begin{equation}
\resizebox{.88\columnwidth}{!}{$
  \begin{aligned}
    \label{eq:lambdafuntheta}
    \lambdaik=
    % \begin{cases}
      -P_{i}^{n}\thetaik-\vec{s}_{i}^{n}[k]\text{, if}\ G^{n}[k]\thetaik \preceq b^{n}[k],
    % \end{cases}
  \end{aligned}
  $}
\end{equation}
with $n\in\{1\mathbin{:}N\}$.

The halfspaces defined by the set of pairs $(G^{j}[k],b^{j}[k])$ represent a combination of active/inactive constraints of ${\bar{\Gamma}_{i}\Uik\preceq\thetaik}$ for a given time $k$, and vary w.r.t. $\vec{v}_{i}[k]$.

The $P_{i}^{j}$ are constructed using $H_{i}$ and $\bar{\Gamma}_{i}$, and $\vec{s}_{i}^{j}$ are constructed using $H_{i}$, $\fik$ and $\bar{\Gamma}_{i}$. The specific construction depends on the active constraints.
For example, if we take the case when all constraints are active, we have ${P_{i}^{\text{ac}}={(\bar{\Gamma}_{i}H_{i}^{-1}\bar{\Gamma}_{i}\T)}^{-1}}$ and ${\vec{s}_{i}^{\text{ac}}[k]=P_{i}^{1}\bar{\Gamma}_{i}H_{i}^{-1}\fik}$.
And if all constraints are inactive, we have ${P_{i}^{\text{in}}=0_{c\times c}}$ and ${\vec{s}_{i}^{\text{in}}=\0_{c}}$.\\
\begin{remark}\label{rmk:P_constant}
The $\vec{s}_{i}^{j}[k]$ depend on time $k$, while $P_{i}^{j}$ do not.
\end{remark}


\begin{challenge}\label{ch:partition_unknown}
  It is important to note that since $\vec{v}_{i}$ is unknown by the coordinator, it cannot anticipate the partition of the space for each agent.
\end{challenge}
\begin{challenge}\label{ch:zone_unknown}
 For the same reason, the values of $\vec{s}_{i}[k]$ are also unknown.
\end{challenge}

 As each constraint can be active or inactive, for a given group of $n$ constraints, we can have at most $N=2^{n}$ different combinations of active/inactive sets and consequently $N$ regions (zones).

 \begin{assumption}
   We assume that none of the combinations of active/inactive constraints are redundant (no linear dependency), nor make the optimization infeasible (no empty intersection).
   Thus we always have $N$ zones.
 \end{assumption}



\subsection{The Attack}\label{ssec:attack}
We suppose the malicious agent choose a function $\gamma_{i}(\cdot)$ to use throughout a given time $k$.
\begin{assumption}
  $\gamma_{i}(\cdot)$ does not change during the \negotiation{} phase for a given time $k$.
\end{assumption}

\begin{assumption}\label{ass:gamma_zero}
  We suppose $\gamma(\cdot)=\0_{c}\iff\lambdai=\0_{c}$
\end{assumption}


\begin{assumption}
  The agent chooses a linear function
  \begin{equation}
\tilde{\lambdai}=\gamma_{i}(\vec{\lambda}_{i})=\Tik\vec{\lambda}_{i},
\end{equation}
  where $\determinant{T}\neq 0$ (from assumption~\ref{ass:gamma_zero}).
\end{assumption}

Such attack function results in a \pwa{} solution for $\lambdaicheat[k]$:
% \begin{equation}
%   \resizebox{.88\columnwidth}{!}{$
%     \label{eq:linear_cheating}
%     \lambdaicheat[k]=
%     \begin{cases}
%       -\Tik P_{i}^{1}\vec{\theta}_{i}-\Tik \vec{s}_{i}^{1}[k]&\text{if}\ G_{1}[k]\thetai \preceq b_{1}[k] \\
%       \qquad\quad \vdots&\qquad\quad \vdots\\
%       -\Tik P_{i}^{N}\vec{\theta}_{i}-\Tik \vec{s}_{i}^{N}[k]&\text{if}\ G_{N}[k]\thetai \preceq b_{N}[k],
%     \end{cases}
%     $}
% \end{equation}
\begin{equation}
  \resizebox{.88\columnwidth}{!}{$
    \label{eq:linear_cheating}
    \lambdaicheat[k]=
    % \begin{cases}
      -\tilde{P}_{i}^{n}[k]\thetaik-\tilde{\vec{s}}_{i}^{n}[k]\text{, if}\ G^{n}[k]\thetaik \preceq b^{n}[k],
    % \end{cases}
    $}
\end{equation}
with $n\in\{1\mathbin{:}N\}$, $\tilde{P}_{i}^{n}[k]=\Tik P_{i}^{n}$ and $\tilde{\vec{s}}_{i}^{n}[k]=\Tik\vec{s}_{i}^{n}[k]$.
Observe that as the function is applied only in $\lambdaik$ it does not affect the hyperplanes generating the zones.

We fix the index for these zones where all constraints are active to $1$, and we can call them the $1$-zones.

\subsection{Detection and mitigation}\label{ssec:DM}
Supposing we have a sequence of $\thetaik$ in a zone $j$, we can estimate the parameters for these zones with
\begin{equation}
  \label{eq:lambdafuntheta_tilde}
\lambdaicheat[k]=\gamma_{i}(\lambdai(\thetaik))=-\widehat{\tilde{P}_{i}^{j}}[k]\thetaik-\widehat{\tilde{\vec{s}}_{i}^{j}}[k].
\end{equation}

\begin{assumption}\label{ass:Pnominal}
  The nominal value of $P_{i}^{j}$ for this given zone $j$, denoted $\bar{P}_{i}^{j}$, is available from reliable attack-free historical data.
\end{assumption}

Since $P_{i}^{n}$ do not change w.r.t.\ time, we can detect a deviation from nominal behavior using ${E_{i}[k] =\|\widehat{\tilde{P}_{i}^{j}}[k]-\bar{P}_{i}^{j}\|_{F}}$.
Let ${d_{i}\in\{0,1\}}$ be an indicator that detects the attack in agent $i$.
If the disturbance $E_{i}[k]$ respects an arbitrary bound
\begin{equation}
  \label{eq:2}
  E_{i}[k]\leq\epsilon_{P},
\end{equation}
then  ${d_{i}=0}$, and no attack is detected. Otherwise, ${d_{i}=1}$, and a change in behavior of agent $i$ is detected.

Using all assumptions presented, we can estimate the inverse of $T_{i}(k)$ with
\begin{equation*}
\widehat{{T_{i}(k)}^{-1}}=\bar{P}_{i}^{j}{\widehat{\tilde{P}_{i}^{j}}[k]}^{-1},
\end{equation*}
if $\widehat{\tilde{P}_{i}^{j}}[k]$ is invertible, and $\widehat{\tilde{P}_{i}^{j}}[k]$ is only invertible when all constraints are active, that means, when ${j=1}$.
\begin{assumption}
  We suppose there exists a $1$-zone for each agent $i$ for every time $k$.
\end{assumption}
And from~\eqref{eq:lambdafuntheta}, we can derive a method to reconstruct $\vec{\lambda}_{i}$:
\begin{equation}
  \label{eq:lambdareconstruction}
  {\vec{\lambda}_{i}}_{\mathrm{rec}}=\widehat{{T_{i}[k]}^{-1}} \tilde{\vec{\lambda}_{i}}
\end{equation}

Since we don't know how to generate points in the $1$-zones, we use the \EM{} algorithm which can potentially identify the parameters of all modes.

\subsection{Expectation Maximization}
In order to estimate $\widehat{\tilde{P}_{i}^{1}}$, we must have enough observed points in the $1$-zones.
We propose to generate points surrounding arbitrary $\bar{\vec{\theta}_{i}}$ in the $1$-zones, and use them to estimate $\widehat{\tilde{P}_{i}^{1}}$.

% TODO(accacio): change unconstrained notation
\todo{
  Let $\optuncUik$ be the solution of the unconstrained version of~\ref{eq:quadratic_case}.
  It is known that its solution is ${ {\optuncUik}=-H_{i}^{-1}\fik}$.
  For the constrained solution we know that the constraints will be inactive if they respect the inequalities $\Theta_{i}\optuncUik\preceq\thetai$.
  If they regard the inequalities, the constrained value is calculated as is, if not it should be projected onto the viable region.
  This way, for all constraints to be active, all inequalities should be disrespected in $\Theta_{i}\optuncUik\preceq\thetai$, thus \[\thetai\prec\Theta_{i}\optuncUik.\]
  % Since $H_{i}:\defpos$, then $H_{i}^{-1}:\defpos$,
  If we choose $\bar{\theta}_{i}=\0$, the constraints will be active when the  will only  that can assure that all constraints are active, then we can estimate ${\widehat{\tilde{P}_{i}^{1}}[k]}$ around this point. Unfortunately, since we don't know the hyperplanes that separates the different zones, some points generated for the estimation can belong to other zones.
  So we use the \EM{} algorithm to estimate the parameter for the $1$-zones, as it can clusterize the points and estimate parameters at the same time.
}


The main objective of the \EM{} algorithm, seen in~\cite{DempsterEtAl1977}, is to find maximum likelihood estimators for models with latent variables.

We will use our estimation problem to illustrate how the algorithm works, and
we will concentrate on the estimation of the parameters for a single agent in a single step $k$, so we drop the subscript $i$ and the time dependency $[k]$ to simplify the notation.

As in~\eqref{eq:lambdafuntheta},  any response variable $\tilde{\vec{\lambda}}$, is a function of an input $\vec{\theta}$, which belongs to a unknown zone ${\set{Z}=\{1\mathbin{:}Z\}}$, Challenge~\ref{ch:zone_unknown}.
The relationship between the input and the response is given by a set of parameters we want to estimate ${\set{P}=\setbuild{(\tilde{P}^{z},\tilde{\vec{s}}^{z})}{z\in\set{Z}}}$.

For an observation ${o\in\set{O}=\{1\mathbin{:}O\}}$, we observe the input and response variables, identified as  ${\random{\vec{\theta}}_{o}}$ and ${\random{\vec{\lambda}}_{o}}$.
As~\eqref{eq:linear_cheating} gives us a multidimensional \pwa{} function, we propose to use an expansion of the model referred as \emph{mixture of switching regressions} in~\cite{QuandtRamsey1978} and \emph{mixture of linear regressions} in~\cite{FariaSoromenho2010}, which we will call \emph{mixture of affine regressions}, since our regressors have a linear term (matrices $\tilde{P}^{z}$) and a constant term (vectors $\tilde{\vec{s}}^{z}$):
% TODO(accacio): change subscript n
\begin{equation}
  \label{eq:linear_cheating_random}
  \randomvec{\lambda}_{o}=
  \begin{cases}
    -\tilde{P}^{1}\randomvec{\theta}_{o}-\tilde{\vec{s}}^{1}&\text{if in zone } 1\\
    \qquad\quad \vdots&\qquad\quad \vdots\\
    -\tilde{P}^{Z}\randomvec{\theta}_{o}-\tilde{\vec{s}}^{Z}&\text{if in zone } Z\\
  \end{cases}.
\end{equation}

Each couple of observed input and response variables $(    \randomvec{\lambda}_{o}, \randomvec{\theta}_{o})$ is associated in this model to a latent unobserved random variable ${\random{z}_{o}\in\set{Z}}$ that indicates from which of the $Z$ affine regression models in~\eqref{eq:linear_cheating_random} the response variable was obtained.
The latent variable $\random{z}_{o}$ follows a categorical prior distribution, with associated probabilities ${\Pi=\{\pi_{1},\dots,\pi_{Z}\}}$:
   \begin{equation}
     \label{eq:prob_zo_equal_z}
\probability{\random{z}_{o}=z}=\pi_{z} \in [0,1], \qquad \sum_{z=1}^{Z} \pi_{z} = 1.
\end{equation}
Since $\vec{\theta}$ is our input,
we consider a non-informative improper probability density function~\cite{ChristensenEtAl2010}
% SL: BTW, maybe we should use different notations for "the probability that some discrete random variable (e.g. z_0) is equal to something, and the probability density function of a continuous random variable (e.g. theta_0 and lambda_0).
\begin{equation}
  \label{eq:theta_almost_surely}
  \probability{\randomvec{\theta}_{o}} \,\propto \,1.
\end{equation}

Given the input and latent variables, the response variable $\random{\lambda}_{o}$ is modeled as a multivariate normal random variable with probability density function
\begin{equation}
  \label{eq:multivariate_gaussian}
\probability{\randomvec{\lambda}_{o}|\randomvec{\theta}_{o},\random{z}_{o}=z; \set{P}^{z}} = \mathcal{N}(\randomvec{\lambda}_{o};f(\randomvec{\theta}_{o};\set{P}^{z}),{\Sigma^{z}}),
\end{equation}
where, following~\eqref{eq:linear_cheating_random}, the mean vector is defined by
\[f(\randomvec{\theta}_{o};(P,\vec{s}))=-{P}\randomvec{\theta}_{o}-{\vec{s}},\]
and the covariance matrix ${\Sigma^{z}}$ tends to $0$.

This mixture of affine regression model is represented as a probabilistic graphical model in Fig.~\ref{fig:model}, and it corresponds to the following factorization of the complete-data (i.e., observed and latent data) likelihood, \cite{Bishop2006}:
\begin{align}\label{eq:completedataLikelihood}
  \probability{\random{\Theta},\random{\Lambda},\random{Z};\set{P}}= \prod_{o=1}^{O}\prod_{z=1}^{Z}\big[&\probability{\randomvec{\lambda}_{o}|\randomvec{\theta}_{o},\random{z}_{o}=z;\set{P}^{z}} \nonumber \\
& \times \probability{\random{z}_{o}=z}\probability{\randomvec{\theta}_{o}}\big]^{\indicator{\random{z}_{o}=z}},
\end{align}

Ideally, we would like to estimate the unknown model parameters $\set{P}$ by maximizing the log-marginal likelihood $\ln \probability{\random{\Theta},\random{\Lambda};\set{P}}$, computed by marginalizing the latent variables $\random{Z}$ in~\eqref{eq:completedataLikelihood}.
Unfortunately, this optimization problem does not admit a closed-form analytical solution.
Instead, we can exploit the latent-variable structure of the model to derive an \EM{} algorithm,~\cite{DempsterEtAl1977}, which is a convergence-guaranteed iterative algorithm ensuring at each iteration a monotonic increase of the log-marginal likelihood.

\begin{figure}[b]
  \centering
  \begin{tikzpicture}
    \draw[thick,blue,rounded corners=10pt] (-1.7,1.2) rectangle (1.7,-1.7);
    \node at (1.2,-1.3) {O};
    \node (pi) at (-2.5,.5) {$\Pi$};
    \node (phi) at (2.5,-1.) {$\set{P}$};

    \graph [edge quotes={fill=white,inner sep=1pt},
    clockwise=3,nodes={circle,draw,rotate=-60,minimum width=1cm}] {
      a/"${\randomvec{\theta}_{o}}$"[rotate=60,fill=lightgray],b/"${\random{\vec{\lambda}}_{o}}$"[rotate=60,fill=lightgray],c/"${\random{z}}_{o}$"[rotate=60];
      {a,c} ->[-latex] b;
      (pi) ->[thick,{Circle[length=3.pt]}-latex] c;
      (phi) ->[thick,{Circle[length=3.pt]}-latex] b;
      };
  \end{tikzpicture}
  \caption{Graph representation of model proposed.}\label{fig:model}
\end{figure}

Now we can formalize the \EM{} problem.
\begin{problem}{Expectation Maximization Problem}\label{pb:EM}

  Given a set of observed data $(\random{\Theta},\random{\Lambda})$, estimate the unknown latent variables $\random{Z}$ and parameter set $\set{P}$ by iteratively maximizing \todo{a function of} the complete-data log likelihood $\ln\probability{\random{\Theta},\random{\Lambda},\random{Z};\set{P}}$.
\end{problem}

Using~\eqref{eq:prob_zo_equal_z},~\eqref{eq:theta_almost_surely}, and~\eqref{eq:multivariate_gaussian} in~\eqref{eq:completedataLikelihood} yields {\color{blue}the following expression of the complete-data log-likelihood:}
\begin{equation}\label{eq:completedataLogLikelihood_complete}
\ln\probability{\random{\Theta},\random{\Lambda},\random{Z};\set{P}}=  \sum_{o=1}^{O}\sum_{z=1}^{Z}{\indicator{\random{z}_{o}=z}}
  \alpha_{zo},
\end{equation}
where ${\alpha_{zo}=\ln{\pi_{z}}+\ln{\mathcal{N}(\randomvec{\lambda}_{o};f(\randomvec{\theta}_{o};\set{P}^{z}),{\Sigma^{z}})}}$.

But as mentioned, we do not observe the complete data $(\random{\Theta},\random{\Lambda},\random{Z})$, instead we observe only $(\random{\Theta},\random{\Lambda})$ and all the information on $\random{Z}$ given these observations is carried by the posterior probabilities  ${\zeta(z_{zo};\set{P})=\probability{\random{z}_{o}=z|\randomvec{\lambda}_{o},\randomvec{\theta}_{o};\set{P}}}$, also called \emph{responsibilities}, which can be calculated as
\todo[Change Notation?]{Change Notation?}
% SL: the notation z_{zo} is a bit confusing and I am not sure it was defined. It's actually related to the fact that you use z_0 as the latent variable and $z$ as the values it can take in \mathcal{Z}. Using another variable for the latter may help clarifying.

\begin{align}
  \label{eq:responsibilities}
\zeta(z_{zo};\set{P})&=\frac{\probability{\random{z}_{o}=z}\probability{\randomvec{\lambda}_{o}|\randomvec{\theta}_{o};\set{P}^{z}}}{\sum\limits_{j=1}^{Z}\probability{\random{z}_{o}=j}\probability{\randomvec{\lambda}_{o}|\randomvec{\theta}_{o};\set{P}^{j}}}\nonumber\\
  &=\frac{\pi_{z}{\mathcal{N}(\randomvec{\lambda}_{o};f(\randomvec{\theta}_{o};\set{P}^{z}),{\Sigma^{z}})}}{\sum\limits_{j=1}^{Z}\pi_{j}\mathcal{N}(\randomvec{\lambda}_{o};f(\randomvec{\theta}_{o};\set{P}^{j}),{\Sigma^{j}})}.
\end{align}

Observe that by taking
\todo[Change Notation?]{Change Notation?}
\begin{equation}\label{eq:argmaxz}
\arg\underset{z}{\max}\ {\zeta_{zo}(;\set{P})},
\end{equation}
we can get the most probable $z$-zone which generated the observation $\randomvec{\lambda}_{o}$.


So, rather than using the complete data log-likelihood~\eqref{eq:completedataLogLikelihood_complete}, which we do not have, since the latent variables are not observed by definition, the \EM{} algorithm uses its expectation with respect to the posterior calculated using a given set of parameter estimates $\set{P}_{\mathrm{cur}}$:
\begin{align}
  \label{eq:completedataLogLikelihood_expectation}
 Q\left(\set{P},\set{P}_{\mathrm{cur}}\right) &= \expectation[{\zeta(z_{zo};\set{P}_{\mathrm{cur}})}]{\ln\probability{\random{\Theta},\random{\Lambda},\random{Z};\set{P}}}
\end{align}
and since \[\expectation[{\zeta(z_{zo};\set{P}_{\mathrm{cur}})}]{\indicator{\random{z}_{o}=z}}=\zeta(z_{zo};\set{P}_{\mathrm{cur}}),\]
we can rewrite~\eqref{eq:completedataLogLikelihood_expectation}:
\begin{align}
  \label{eq:completedataLogLikelihood_expectation_developed}
Q\left(\set{P},\set{P}_{\mathrm{cur}}\right) &= \sum_{o=1}^{O}\sum_{z=1}^{Z}  \zeta(z_{zo};\set{P}_{\mathrm{cur}})\alpha_{zo},
\end{align}
\todo{\begin{remark}
For the first iteration, the model parameters must be initialized. A discussion about the initialization of the parameters is beyond the scope of this article, and we refer the reader to~\cite{Bishop2006},~\cite{DempsterEtAl1977} and their references.
\end{remark}}

Then we can find a new estimate of $\set{P}$ that maximizes $Q(\set{P},\set{P}_{\mathrm{cur}})$:
\begin{equation} \label{eq:Mstep}
  \set{P}_{\mathrm{new}}=\underset{\set{P}}{\argmax}\ Q(\set{P},\set{P}^{\mathrm{cur}}).
\end{equation}
For the next iteration of the algorithm, this new estimate $\set{P}_{\mathrm{new}}$ will be used as $\set{P}^{\mathrm{cur}}$.

With this information we can describe the \EM{} algorithm in two parts, first calculate the responsibilities $\zeta(z_{zo};\set{P}_{\mathrm{cur}})$, and then update the parameters.
Algorithm~\ref{alg:em} adapted from~\mbox{\cite[Chapter 9]{Bishop2006}} describes the steps.

\begin{algorithm2e}[h]
  \DontPrintSemicolon%
  Initialize parameters $\set{P}_{\mathrm{new}}$\;
  \Repeat{$\set{P}_{\mathrm{cur}}$ converge}{
    $\set{P}_{\mathrm{cur}}=\set{P}_{\mathrm{new}}$\;
  \textbf{E step} Evaluate responsibilities~\eqref{eq:responsibilities}\;
  \textbf{M step} Reestimate parameters~\eqref{eq:Mstep}\;
}
 \caption{Expectation Maximization}\label{alg:em}
\end{algorithm2e}

Here we introduce a variable ${\vec{\phi}^{z}={[\vectorize{\tilde{P}^{z}}^{T}\ {(\tilde{\vec{s}}^{z})}^{T} ]}^{T}}$ so we can calculate the new estimates of $\set{P}$ from~\eqref{eq:Mstep}. Using the KKT conditions~\cite{BoydVandenberghe2004}, we can find an optimal solution for the problem in~\eqref{eq:Mstep}, by
taking the gradients of~\eqref{eq:completedataLogLikelihood_expectation} with respect to vectors $\vec{\phi}^{z}$ and making them vanish.
Because of the multidimensional nature of the problem, some matrix operations are needed to synthesize the results.
After those operations, we have a matricial solution that yields the optimal estimates $\vec{\phi}_{z}^{\mathrm{new}}$:
\begin{equation}
  \label{eq:mstepestimation}
  \vec{\phi}_{z}^{\mathrm{new}}=\pseudoinv{(\Xi_{z}\random{\Omega})}\Xi_{z}\vectorize{\random{\Lambda}},
\end{equation}
where
${\random{\Omega}=[\hadamard{(\Upsilon \random{\Theta}\Delta)}{Y};G]}$,
with matrices
${\Upsilon=\kron{\1_{n}^{T}}{I_{n}}}$,
${\Delta=\kron{I_{N}}{\1_{n}^{T}}}$,
${Y=\kron{G}{\1_{n}}}$,
${G=\kron{\1_{N}^{T}}{I_{n}}}$,
and
\[{\Xi_{z}={\diag(\sqrt{{\zeta(z_{z1};\set{P}_{\mathrm{cur}})}}I_{n},\cdots,\sqrt{{\zeta(z_{zO};\set{P}_{\mathrm{cur}})}}I_{n})}}.\]
% SL: I find it surprising that you have square roots of the responsabilities in this equation. Are you sure it is correct?

As we can see,~\eqref{eq:mstepestimation} is the solution of a weighted Least-Squares, having the responsibilities as weights, adjusting the contribution of all observations to the regression model of index $z$.
We can see some similarities to the K-planes algorithm (see~\cite{BradleyMangasarian2000}), but \EM{} is more compromising.
Instead of affecting the observed data to a zone with 100\% of certainty (\emph{hard assignment}), \EM{} uses the responsibilities (\emph{soft assignment}) for each zone.
Then, when we solve the \textbf{M Step}, rather than using only the data assigned to update the parameters of a certain zone, we take into account all data, whose contribution to the update is weighted by their associated responsibilities.


Once the estimates $\vec{\phi}_{z}^{\mathrm{new}}$ converge, we can reconstruct the estimates $\tilde{P}^{z}$ and $\tilde{\vec{s}}^{z}$, and use in our mitigation scheme proposed in \S\ref{ssec:DM}.

\todo {
  Observe that not necessarily the parameters estimated associated to a value z corresponds to the z shown in
}
% \begin{equation*}
%   p(\randomvec{x})=\sum_{i=0}^{N}\pi_{i} \mathcal{N}(\random{y};f_{i}(\randomvec{x}),\Sigma_{i})
% \end{equation*}

% \begin{equation}
%   \mathcal{N}(\random{y}; {\mu}_{i},\Sigma_{i})=\frac{1}{{\sqrt{2\pi\sigma_{i}^{2}}}}e^{-\frac{(\random{y}-{\mu}_{i})^{2}}{2\sigma^{2}}}
% \end{equation}

% for a $D-$dimensional gaussian we have:
% \begin{equation}
%   \mathcal{N}(\randomvec{y}; \vec{\mu}_{i},\Sigma_{i})=\frac{1}{{{(2\pi)}^{D/2}}{|\Sigma_{i}|^{\frac{1}{2}}}}e^{-\frac{1}{2}\norm{\randomvec{y}-\vec{\mu}_{i}}^{2}_{\Sigma_{i}^{-1}}}
% \end{equation}

% \begin{figure}[b]
%   \centering
%   \scriptsize \def\svgwidth{0.49\textwidth}
%   \includegraphics[width=\columnwidth]{pwagaussian.pdf}
%   \caption{Example of Gaussian Probability density functions used in mixture for identification of a 2D Piecewise Affine function with 2 modes, where \todo[verify colormap]{black represents 0 probability and white maximum }}\label{fig:pwagaussian}
% \end{figure}
\todo{Simulated annealing as in \cite{OzerovFevotte2010}}

\subsection{Safe dMPC Algorithm}\label{ssec:safe_algo}
\SetKwBlock{negotPhase}{ Negotiation Phase:}{}
\SetKwBlock{detectPhase}{ Detection Phase:}{}
\begin{algorithm2e}[h]
  \DontPrintSemicolon
  \detectPhase{
    Coordinator sends sequence of $\vec{\theta}_{i}^{o}$, $o\in\set{O}$ \;
    Subsystems solve~\eqref{eq:DOP_local}, and send $\tilde{\vec{\lambda}}^{o}_{i}$, $o\in\set{O}$\;
    Coordinator estimates $\widehat{\tilde{P}_{i}^{1}}[k]$ and $\widehat{\tilde{\vec{s}}_{i}^{1}}[k]$ with \EM{}\;
    Coordinator computes $d_{i}$ using~\eqref{eq:2}\;
  }
  \negotPhase{
  Coordinator initializes $\vec{\theta}^{(0)}$ \;
  $p:=0$\;

  \Repeat{$\|\vec{\theta}^{(p)} -\vec{\theta}^{(p-1)}\|\leq\epsilon$}{
  Subsystems solve~\eqref{eq:DOP_local}, and send $\vec{\lambda}^{\star}_{i}(\vec{\theta}\p)$\;

  Coordinator updates allocation~\eqref{eq:thetaNegot} using adequate versions of $\vec{\lambda}_{i}\p$ for each agent:
  $\tilde{\vec{\lambda}}_{i}\p$, if $d_{i}=0$ and ${\vec{\lambda}_{i}}_{\mathrm{rec}}$, if ${d_{i}=1}$\;
  $p:=p+1$
 }}
 \caption{Secure DMPC.}\label{alg:safeDMPC}
\end{algorithm2e}

\section{Simulation}
\begin{figure}[h]
  \centering
 \includegraphics[width=\columnwidth]{airtemp_roomI/__ErrorWX_command_normErrH.pdf}
  \caption{Air temperature in room I and the Frobenius norm of the decision variable $E_{I}[k]$ for different scenarios: nominal (N), selfish behavior without correction (S),
and selfish behavior with correction.}\label{fig:response3Scenarios}
\end{figure}
\begin{figure}[h]
  \centering
 \includegraphics[width=\columnwidth]{airtemp_roomI/control.pdf}
  \caption{Control applied in all rooms for the 3 different scenarios: nominal, selfish behavior without correction, and selfish behavior with correction (C).}\label{fig:response3Scenarios}
\end{figure}

% TODO(accacio): Verify
\begin{table}[t]
  \centering
  \caption{Comparison of costs $J_{i}$}\label{tab:costsGlobalLocal}
  \begin{tabular}[t]{cccc} \toprule
    Agent  & Nominal & Selfish & Selfish + Correction\\
    \midrule
    I & -11468 &  -9074 & -11468 \\
    II & -6536 &  -7151 & -6536 \\
    III & -3192 &  -4052 & -3192 \\
    IV & -2849 &  -3694 & -2849 \\
    Global & -24044 &  -23971 & -24044 \\


    \bottomrule
  \end{tabular}
\end{table}

\section{Conclusion}

A conclusion section is not required. Although a conclusion may review
the main points of the paper, do not replicate the abstract as the
conclusion. A conclusion might elaborate on the importance of the work
or suggest applications and extensions.

% \nocite{*}
\bibliography{bibliography}
% \todo[Change bibliography to the one used in the aux]{}
\end{document}
